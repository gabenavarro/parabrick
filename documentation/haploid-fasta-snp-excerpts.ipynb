{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c47dad",
   "metadata": {},
   "source": [
    "# From FASTQ to **Personalized FASTA (SNP Excerpts)** for Genome Language Models  \n",
    "**fastp ➜ Parabricks FQ2BAM (GPU WGS) ➜ Parabricks HaplotypeCaller (GPU) ➜ bcftools filter ➜ SNP-window consensus FASTA**\n",
    "\n",
    "---\n",
    "\n",
    "Genome language models (GLMs) are most informative when they “see” **subject-specific variants** rather than a generic reference. This notebook shows a reproducible, GPU-accelerated path from raw short-read FASTQs to a **personalized FASTA composed of SNP-centered sequence windows**, ready for downstream LM work. Along the way we keep to community best practices while noting where GLM-specific choices (tokenization, windowing, heterozygosity) matter.\n",
    "\n",
    "### A (very) brief lineage\n",
    "\n",
    "- **FASTQ preprocessing got faster & simpler.** Instead of chaining multiple tools for QC, adapter/quality trimming, and UMI handling, **fastp** consolidated these into one multithreaded binary with built-in reports. [fastp paper][fastp-paper]; [fastp GitHub][fastp-github].  \n",
    "- **Mapping standardized on BWA-MEM + SAM/BAM.** BWA-MEM (2013) became the workhorse for short/long reads; SAM/BAM (2009) provided the interoperable alignment container used everywhere. [BWA-MEM][bwa-mem]; [SAM/BAM][sam-bam].  \n",
    "- **Variant calling best practices.** The **GATK** pipeline systematized mark-duplicates, BQSR, and HaplotypeCaller’s **local de-novo assembly** for robust germline calling. [GATK Best Practices][gatk-best-practices].  \n",
    "- **GPUs made production-scale genomics practical.** Suites like **NVIDIA Parabricks** port the canonical CPU tools to GPUs (same results, much faster), enabling cohort-scale turnarounds and reduced cloud cost. [Parabricks FQ2BAM][pbr-fq2bam]; [Parabricks overview][pbr-overview]; [GPU scaling][gpu-scaling].\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Preprocess reads with **fastp**\n",
    "\n",
    "**Why:** Single-step adapter/quality trimming with rich QC, at speed.  \n",
    "**Example:**\n",
    "```bash\n",
    "fastp -i sample_R1.fastq.gz -I sample_R2.fastq.gz \\\n",
    "      -o sample.trim.R1.fq.gz -O sample.trim.R2.fq.gz \\\n",
    "      --detect_adapter_for_pe --cut_mean_quality 20 \\\n",
    "      --length_required 50 --thread 16 \\\n",
    "      --html fastp.html --json fastp.json\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Map & produce BAM with **Parabricks FQ2BAM** (GPU)\n",
    "\n",
    "**Why:** GPU-accelerated BWA-MEM + sorting + duplicate marking (+ optional BQSR) with CPU-parity outputs.\n",
    "\n",
    "```bash\n",
    "pbrun fq2bam \\\n",
    "  --ref hg38.fa \\\n",
    "  --in-fq sample.trim.R1.fq.gz sample.trim.R2.fq.gz \\\n",
    "  --out-bam sample.bam \\\n",
    "  --knownSites dbsnp.vcf.gz \\\n",
    "  --markdups --BQSR --num-threads 32\n",
    "```\n",
    "\n",
    "References: [BWA-MEM][bwa-mem], [SAM/BAM][sam-bam], [GATK Best Practices][gatk-best-practices], [Parabricks FQ2BAM][pbr-fq2bam], [Parabricks overview][pbr-overview], [GPU scaling][gpu-scaling].\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Call germline variants with **Parabricks HaplotypeCaller** (GPU)\n",
    "\n",
    "**Why:** GATK’s **local assembly** improves accuracy in complex loci; Parabricks mirrors behavior at GPU speeds.\n",
    "\n",
    "```bash\n",
    "pbrun haplotypecaller \\\n",
    "  --ref hg38.fa \\\n",
    "  --in-bam sample.bam \\\n",
    "  --out-variants sample.g.vcf.gz \\\n",
    "  --emit-ref-confidence GVCF --gvcf\n",
    "```\n",
    "\n",
    "(Optionally joint-genotype multiple gVCFs before filtering.)\n",
    "\n",
    "References: [HaplotypeCaller docs][haplotypecaller-docs], [GATK Best Practices][gatk-best-practices], [Parabricks overview][pbr-overview].\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Filter to **high-confidence SNPs**\n",
    "\n",
    "Use transparent, auditable filters (tune to coverage/organism). Example:\n",
    "\n",
    "```bash\n",
    "# Keep biallelic SNPs with minimal depth/quality standards\n",
    "bcftools view -m2 -M2 -v snps sample.g.vcf.gz -Oz -o sample.snps.vcf.gz\n",
    "tabix -p vcf sample.snps.vcf.gz\n",
    "\n",
    "bcftools filter -i 'TYPE=\"snp\" && DP>=10 && GQ>=20 && MQ>=40' \\\n",
    "  sample.snps.vcf.gz -Oz -o sample.snps.filtered.vcf.gz\n",
    "tabix -p vcf sample.snps.filtered.vcf.gz\n",
    "```\n",
    "\n",
    "References: [bcftools manual][bcftools-manual].\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Build **SNP-centered FASTA windows** (personalized)\n",
    "\n",
    "For language models that operate on **short excerpts**, extract windows ±*W* bp around each SNP and write a FASTA with one record per window.\n",
    "\n",
    "**5a. Prepare BED of SNP loci and expand to windows**\n",
    "\n",
    "```bash\n",
    "# 1-bp BED of SNP sites (BED is 0-based, half-open)\n",
    "bcftools query -f '%CHROM\\t%POS\\t%ID\\n' sample.snps.filtered.vcf.gz \\\n",
    "| awk 'BEGIN{OFS=\"\\t\"} {start=$2-1; print $1, start, $2, $3}' \\\n",
    "> snps.1bp.bed\n",
    "\n",
    "# Expand by W bp on each side (example: W=100, giving 201-bp windows)\n",
    "bedtools slop -i snps.1bp.bed -g hg38.chrom.sizes -b 100 > snps.200bp.bed\n",
    "```\n",
    "\n",
    "**5b. Write consensus sequence per window (choose het handling)**\n",
    "\n",
    "```bash\n",
    "# Haplotype options:\n",
    "#   -H 1 or -H 2    -> pick a phased haplotype (good for generation)\n",
    "#   -I (--iupac-codes) -> retain heterozygosity via IUPAC (good for embeddings)\n",
    "\n",
    "bcftools consensus \\\n",
    "  -f hg38.fa \\\n",
    "  -s SAMPLE_ID \\\n",
    "  -H 1 \\\n",
    "  -R snps.200bp.bed \\\n",
    "  --allow-overlaps \\\n",
    "  sample.snps.filtered.vcf.gz > SAMPLE.snp_windows.fa\n",
    "```\n",
    "\n",
    "Notes: `bcftools consensus` applies genotype calls onto the reference and can limit output to target regions (`-r/-R`). IUPAC output preserves heterozygous ambiguity; haplotype selection produces unambiguous A/C/G/T strings. [bcftools consensus how-to][bcftools-consensus]; [bcftools manual][bcftools-manual]. For region math, we used **BEDTools**. [BEDTools paper][bedtools-paper].\n",
    "\n",
    "---\n",
    "\n",
    "## Designing FASTA **for LMs**: NLU vs NLG\n",
    "\n",
    "Modern genomics LMs vary in tokenization (single nucleotides, **k-mers**, or **BPE-style** units) and context length, which changes how you should package sequences. DNABERT popularized overlapping **k-mers** (often 6-mers) for classification tasks; newer models explore BPE-like tokenization and very long contexts (e.g., **HyenaDNA**). [DNABERT][dnabert-paper]; [DNABERT repo][dnabert-code]; [Nucleotide Transformer][nt-paper]; [DNABERT-2][dnabert2-paper]; [HyenaDNA][hyenadna-paper].\n",
    "\n",
    "**If you’ll use *final-layer hidden states* (NLU/embedding features):**\n",
    "\n",
    "* Prefer **fixed-length windows** (e.g., 201/401 bp) for consistent batching and pooling.\n",
    "* **Keep heterozygosity** via **IUPAC** (`bcftools consensus -I`) so embeddings encode zygosity without duplicating windows.\n",
    "* Use a clear FASTA header schema to carry metadata you’ll need later (e.g., `>rs123|chr1:1,234,567|W=200|GENE=...`).\n",
    "* Downstream, pool token embeddings or use a special aggregate token (analogous to **\\[CLS]** in BERT) for per-window features. [BERT][bert-paper].\n",
    "\n",
    "**If you’ll use *raw token logits* (NLG/generative scoring or sampling):**\n",
    "\n",
    "* Prefer **unambiguous haplotype strings** (`-H 1` or `-H 2`), avoiding IUPAC—ambiguous codes can confuse next-token prediction.\n",
    "* Maintain **contiguity** within each record (do not interleave far-apart windows in one sequence); if you concatenate windows, separate with a consistent **sentinel motif** (e.g., long runs of `N`) your tokenizer handles gracefully.\n",
    "* Match the model’s tokenizer: for **k-mer LMs**, ensure record lengths align to the stride; for **BPE/single-nt LMs**, plain A/C/G/T/N is fine. [DNABERT][dnabert-paper]; [DNABERT-2][dnabert2-paper].\n",
    "\n",
    "> **Rule of thumb:**\n",
    ">\n",
    "> * **NLU/embeddings:** IUPAC hets + fixed windows → feature vectors for classifiers/regressors.\n",
    "> * **NLG/logits:** pick a haplotype, avoid ambiguity, keep sequences contiguous for stable next-token behavior.\n",
    "\n",
    "---\n",
    "\n",
    "## Why SNP-window FASTA helps\n",
    "\n",
    "SNP-centric windows give LMs **direct access to the causal bases** and their immediate context, reducing sequence redundancy and I/O while retaining the signal most relevant to variant-aware tasks. This format also scales well to cohorts using **GPU pipelines** for mapping/calling and efficient **bcftools** filtering/consensus for final assembly. [GPU scaling][gpu-scaling]; [bcftools manual][bcftools-manual]; [bcftools consensus][bcftools-consensus].\n",
    "\n",
    "---\n",
    "\n",
    "## Minimal end-to-end checklist\n",
    "\n",
    "1. **fastp**: trim & QC → `sample.trim.*.fq.gz`.\n",
    "2. **Parabricks FQ2BAM**: map, sort, mark-dups (±BQSR) → `sample.bam`.\n",
    "3. **Parabricks HaplotypeCaller**: call variants → `sample.g.vcf.gz` (±joint-genotype).\n",
    "4. **bcftools**: select high-confidence **SNPs** → `sample.snps.filtered.vcf.gz`.\n",
    "5. **BEDTools**: expand SNPs to ±*W* windows → `snps.<2W+1>bp.bed`.\n",
    "6. **bcftools consensus**: write **personalized SNP-window FASTA** → `SAMPLE.snp_windows.fa`.\n",
    "\n",
    "---\n",
    "\n",
    "## References (selected)\n",
    "\n",
    "* **Preprocessing & Alignment**\n",
    "  Chen *et al.* 2018 — **fastp**: ultra-fast FASTQ preprocessor. [fastp paper][fastp-paper]; [fastp GitHub][fastp-github].\n",
    "  Li 2013 — **BWA-MEM**. [BWA-MEM][bwa-mem].\n",
    "  Li *et al.* 2009 — **SAM/BAM** format. [SAM/BAM][sam-bam].\n",
    "\n",
    "* **Variant Calling & GPUs**\n",
    "  Van der Auwera *et al.* 2013 — **GATK Best Practices**. [GATK Best Practices][gatk-best-practices].\n",
    "  **Parabricks** docs — **FQ2BAM**, **HaplotypeCaller**. [pbr-fq2bam][pbr-fq2bam]; [haplotypecaller-docs][haplotypecaller-docs]; [Parabricks overview][pbr-overview].\n",
    "  Taylor-Weiner *et al.* 2019 — **GPU scaling** in genomics. [GPU scaling][gpu-scaling].\n",
    "\n",
    "* **Consensus & Regions**\n",
    "  **bcftools** manual & how-to — filtering and `consensus`. [bcftools-manual][bcftools-manual]; [bcftools-consensus][bcftools-consensus].\n",
    "  Quinlan & Hall 2010 — **BEDTools**. [BEDTools paper][bedtools-paper].\n",
    "\n",
    "* **Genome LMs & tokenization**\n",
    "  Ji *et al.* 2021 — **DNABERT**. [DNABERT][dnabert-paper]; [DNABERT repo][dnabert-code].\n",
    "  Dalla-Torre *et al.* 2023/2025 — **Nucleotide Transformer**. [NT paper][nt-paper].\n",
    "  Zhou *et al.* 2024 — **DNABERT-2** (BPE tokenization). [DNABERT-2][dnabert2-paper].\n",
    "  Nguyen *et al.* 2023 — **HyenaDNA** (ultra-long contexts). [HyenaDNA][hyenadna-paper].\n",
    "  Devlin *et al.* 2018/2019 — **BERT** (NLU/\\[CLS] pooling). [BERT][bert-paper].\n",
    "\n",
    "---\n",
    "\n",
    "<!-- Reference-style link definitions -->\n",
    "\n",
    "[fastp-paper]: https://academic.oup.com/bioinformatics/article/34/17/i884/5093234 \"fastp: an ultra-fast all-in-one FASTQ preprocessor\"\n",
    "[fastp-github]: https://github.com/OpenGene/fastp \"OpenGene/fastp\"\n",
    "[bwa-mem]: https://arxiv.org/pdf/1303.3997 \"Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM\"\n",
    "[sam-bam]: https://pmc.ncbi.nlm.nih.gov/articles/PMC2723002/ \"The Sequence Alignment/Map format and SAMtools\"\n",
    "[gatk-best-practices]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4243306/ \"From FastQ data to high confidence variant calls (GATK Best Practices)\"\n",
    "[pbr-fq2bam]: https://docs.nvidia.com/clara/parabricks/4.4.0/Documentation/ToolDocs/man_fq2bam.html \"Parabricks FQ2BAM (BWA-MEM + GATK)\"\n",
    "[haplotypecaller-docs]: https://docs.nvidia.com/clara/parabricks/4.4.0/Documentation/ToolDocs/man_haplotypecaller.html \"Parabricks HaplotypeCaller\"\n",
    "[pbr-overview]: https://docs.nvidia.com/clara/parabricks/latest/Tutorials/FQ2BAM_Tutorial.html \"NVIDIA Parabricks overview & FQ2BAM tutorial\"\n",
    "[gpu-scaling]: https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1836-7 \"Scaling computational genomics to millions of individuals with GPUs\"\n",
    "[bcftools-manual]: https://samtools.github.io/bcftools/bcftools.html \"bcftools manual\"\n",
    "[bcftools-consensus]: https://samtools.github.io/bcftools/howtos/consensus-sequence.html \"bcftools consensus how-to\"\n",
    "[bedtools-paper]: https://academic.oup.com/bioinformatics/article/26/6/841/244688 \"BEDTools: a flexible suite of utilities for comparing genomic features\"\n",
    "[dnabert-paper]: https://academic.oup.com/bioinformatics/article/37/15/2112/6128680 \"DNABERT: pre-trained BERT for DNA sequences\"\n",
    "[dnabert-code]: https://github.com/jerryji1993/DNABERT \"DNABERT GitHub repository\"\n",
    "[nt-paper]: https://www.biorxiv.org/content/10.1101/2023.01.11.523679v3 \"The Nucleotide Transformer\"\n",
    "[dnabert2-paper]: https://arxiv.org/html/2306.15006v2 \"DNABERT-2: Efficient Foundation Model for Genomics\"\n",
    "[hyenadna-paper]: https://papers.neurips.cc/paper_files/paper/2023/file/86ab6927ee4ae9bde4247793c46797c7-Paper-Conference.pdf \"HyenaDNA: Long-Range Genomic Sequence Modeling\"\n",
    "[bert-paper]: https://arxiv.org/abs/1810.04805 \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"\n",
    "\n",
    "```\n",
    "::contentReference[oaicite:0]{index=0}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd678df",
   "metadata": {},
   "source": [
    "## Import wrapper functions for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9aefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from typing import Dict\n",
    "\n",
    "# Configurations\n",
    "THREADS = 16\n",
    "MEMORY = 128\n",
    "MIN_VAR_QUAL = 30\n",
    "MIN_DEPTH = 6\n",
    "MIN_VAR_FREQ = 0.6  # For haploid, variants should be majority frequency or greater\n",
    "MAX_DEPTH = 500\n",
    "\n",
    "\n",
    "def trim_fastq(\n",
    "    job: Dict[str, str],\n",
    "    min_illumina_quality: int = 20,\n",
    "    min_illumina_length: int = 50,\n",
    "    min_illumina_complexity: int = 30,\n",
    "):\n",
    "    print(job[\"OUTPUT_PREFIX\"])\n",
    "    cmd = [\n",
    "        \"/opt/fastp\",\n",
    "        \"-i\",\n",
    "        job[\"UNPROCESSED_FASTQ_R1\"],\n",
    "        \"-I\",\n",
    "        job[\"UNPROCESSED_FASTQ_R2\"],\n",
    "        \"-o\",\n",
    "        job[\"FASTQ_R1\"],\n",
    "        \"-O\",\n",
    "        job[\"FASTQ_R2\"],\n",
    "        \"-w\",\n",
    "        \"16\",\n",
    "        \"-q\",\n",
    "        str(min_illumina_quality),\n",
    "        \"--detect_adapter_for_pe\",\n",
    "        \"--length_required\",\n",
    "        str(min_illumina_length),\n",
    "        \"-c\",\n",
    "        \"-y\",\n",
    "        \"-Y\",\n",
    "        str(min_illumina_complexity),\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"w\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def alignment(job: Dict[str, str]):\n",
    "    print(job[\"OUTPUT_PREFIX\"])\n",
    "    cmd = [\n",
    "        \"pbrun\",\n",
    "        \"fq2bam\",\n",
    "        \"--ref\",\n",
    "        job[\"REF_FASTA\"],\n",
    "        \"--in-fq\",\n",
    "        job[\"FASTQ_R1\"],\n",
    "        job[\"FASTQ_R2\"],\n",
    "        \"--out-bam\",\n",
    "        job[\"BAM_FILE\"],\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def variant_calling(job: Dict[str, str]):\n",
    "    print(job[\"OUTPUT_PREFIX\"])\n",
    "    cmd = [\n",
    "        \"pbrun\",\n",
    "        \"haplotypecaller\",\n",
    "        \"--ref\",\n",
    "        job[\"REF_FASTA\"],\n",
    "        \"--in-bam\",\n",
    "        job[\"BAM_FILE\"],\n",
    "        \"--out-variants\",\n",
    "        job[\"RAW_VCF\"],\n",
    "        \"--ploidy\",\n",
    "        \"1\",\n",
    "        \"--minimum-mapping-quality\",\n",
    "        \"20\",\n",
    "        \"--haplotypecaller-options\",\n",
    "        \"-standard-min-confidence-threshold-for-calling 10\",\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def basic_snp_filter(job: Dict[str, str]):\n",
    "    print(job[\"OUTPUT_PREFIX\"])\n",
    "    cmd = [\n",
    "        \"bcftools\",\n",
    "        \"view\",\n",
    "        \"-i\",\n",
    "        f\"QUAL >= {MIN_VAR_QUAL} && INFO/DP >= {MIN_DEPTH} && INFO/DP <= {MAX_DEPTH}\",\n",
    "        job[\"RAW_VCF\"],\n",
    "        \"-O\",\n",
    "        \"v\",\n",
    "        \"-o\",\n",
    "        job[\"FILTERED_VCF\"],\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def haploid_snp_filter(job: Dict[str, str]):\n",
    "    print(job[\"OUTPUT_PREFIX\"])\n",
    "    cmd = [\n",
    "        \"bcftools\",\n",
    "        \"view\",\n",
    "        \"-i\",\n",
    "        f\"FORMAT/AD[0:1]/(FORMAT/AD[0:0]+FORMAT/AD[0:1]) >= {MIN_VAR_FREQ}\",\n",
    "        job[\"FILTERED_VCF\"],\n",
    "        \"-O\",\n",
    "        \"v\",\n",
    "        \"-o\",\n",
    "        job[\"HIGH_CONF_VCF\"],\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def generate_fasta(job: Dict[str, str]):\n",
    "    print(job[\"OUTPUT_PREFIX\"])\n",
    "    cmd1 = [\n",
    "        \"bcftools\",\n",
    "        \"norm\",\n",
    "        \"-f\",\n",
    "        job[\"REF_FASTA\"],\n",
    "        \"-m\",\n",
    "        \"-both\",\n",
    "        job[\"HIGH_CONF_VCF\"],\n",
    "        \"-O\",\n",
    "        \"v\",\n",
    "        \"-o\",\n",
    "        f\"{job['HIGH_CONF_VCF']}.normalized.vcf\",\n",
    "    ]\n",
    "    cmd2 = [\n",
    "        \"bcftools\",\n",
    "        \"view\",\n",
    "        f\"{job['HIGH_CONF_VCF']}.normalized.vcf\",\n",
    "        \"-Oz\",\n",
    "        \"-o\",\n",
    "        f\"{job['HIGH_CONF_VCF']}.normalized.vcf.gz\",\n",
    "    ]\n",
    "    cmd3 = [\"bcftools\", \"index\", f\"{job['HIGH_CONF_VCF']}.normalized.vcf.gz\"]\n",
    "    cmd4 = [\n",
    "        \"bcftools\",\n",
    "        \"consensus\",\n",
    "        \"-f\",\n",
    "        job[\"REF_FASTA\"],\n",
    "        \"-o\",\n",
    "        job[\"CONSENSUS_FASTA\"],\n",
    "        f\"{job['HIGH_CONF_VCF']}.normalized.vcf.gz\",\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        for cmd in [cmd1, cmd2, cmd3, cmd4]:\n",
    "            subprocess.run(\n",
    "                cmd,\n",
    "                stdout=f_out,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                check=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f669f1e",
   "metadata": {},
   "source": [
    "### Preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf08ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/workspace/datasets\"\n",
    "study_dir = f\"{base}/haploid\"\n",
    "bam_dir = f\"{study_dir}/bam\"\n",
    "vcf_dir = f\"{study_dir}/vcf\"\n",
    "tmp_dir = f\"{study_dir}/tmp\"\n",
    "fastq_dir = f\"{study_dir}/fastq\"\n",
    "fastq_raw_delimiters = [\"_unprocessed_illumina_\"]\n",
    "\n",
    "# Create directories for files\n",
    "!mkdir -p $base\n",
    "!mkdir -p $study_dir\n",
    "!mkdir -p $bam_dir\n",
    "!mkdir -p $vcf_dir\n",
    "!mkdir -p $tmp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess fasta file\n",
    "fasta_file = f\"{study_dir}/fasta/GCA_000027005.1_ASM2700v1_genomic.fna\"\n",
    "genomic_gtf = f\"{study_dir}/fasta/genomic.gtf\"\n",
    "\n",
    "# Index fasta with BWA\n",
    "!/opt/bwa/bwa index $fasta_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2182c2",
   "metadata": {},
   "source": [
    "### Build jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_files = [\n",
    "    f\"{fastq_dir}/{i}\"\n",
    "    for i in os.listdir(fastq_dir)\n",
    "    if all([j in i for j in fastq_raw_delimiters])\n",
    "]\n",
    "sample_names = [\"your-sample-names\"]\n",
    "# My process to identify filenames based on path\n",
    "# sample_names = sorted(list(set([i.split(\"fastq_unprocessed_illumina_\")[-1].split(\"_R\")[0] for i in fastq_files])))\n",
    "\n",
    "jobs = [\n",
    "    {\n",
    "        \"UNPROCESSED_FASTQ_R1\": [\n",
    "            i for i in fastq_files if sample_name in i and \"_R1.\" in i\n",
    "        ][0],\n",
    "        \"UNPROCESSED_FASTQ_R2\": [\n",
    "            i for i in fastq_files if sample_name in i and \"_R2.\" in i\n",
    "        ][0],\n",
    "        \"FASTQ_R1\": [\n",
    "            i.replace(\"_unprocessed_\", \"_trimmed_\")\n",
    "            for i in fastq_files\n",
    "            if sample_name in i and \"_R1.\" in i\n",
    "        ][0],\n",
    "        \"FASTQ_R2\": [\n",
    "            i.replace(\"_unprocessed_\", \"_trimmed_\")\n",
    "            for i in fastq_files\n",
    "            if sample_name in i and \"_R2.\" in i\n",
    "        ][0],\n",
    "        \"REF_FASTA\": fasta_file,\n",
    "        \"ANNOTATION_GTF\": genomic_gtf,\n",
    "        \"OUTPUT_PREFIX\": sample_name,\n",
    "        \"BAM_FILE\": f\"{study_dir}/bam/{sample_name}.sorted.bam\",\n",
    "        \"RAW_VCF\": f\"{study_dir}/vcf/{sample_name}.raw.vcf\",\n",
    "        \"FILTERED_VCF\": f\"{study_dir}/vcf/{sample_name}.filtered.vcf\",\n",
    "        \"HIGH_CONF_VCF\": f\"{study_dir}/vcf/{sample_name}.high_confidence.vcf\",\n",
    "        \"CONSENSUS_FASTA\": f\"{study_dir}/fasta/{sample_name}.consensus.fasta\",\n",
    "        \"STATS_FILE\": f\"{study_dir}/{sample_name}.stats.txt\",\n",
    "        \"LOG_FILE\": f\"{study_dir}/{sample_name}.pipeline.log\",\n",
    "    }\n",
    "    for sample_name in sample_names\n",
    "]\n",
    "print(len(jobs))\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4849349",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in jobs:\n",
    "    trim_fastq(job)\n",
    "    alignment(job)\n",
    "    variant_calling(job)\n",
    "    basic_snp_filter(job)\n",
    "    haploid_snp_filter(job)\n",
    "    generate_fasta(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c24b5f",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Chen S. *et al.* (2018) **fastp**: an ultra-fast all-in-one FASTQ preprocessor. *Bioinformatics*. ([paper][fastp-paper], [code][fastp-github])\n",
    "2. Li H. (2013) **BWA-MEM**: aligning sequence reads and contigs. *arXiv*. ([preprint][bwa-mem])\n",
    "3. Li H. *et al.* (2009) **The SAM/BAM format and SAMtools**. *Bioinformatics*. ([article][sam-bam])\n",
    "4. Van der Auwera G.A. *et al.* (2013) **From FastQ data to high-confidence variant calls**. *Curr Protoc Bioinformatics*. ([overview][gatk-best-practices])\n",
    "5. **GATK HaplotypeCaller** documentation. ([page][haplotypecaller-docs])\n",
    "6. **NVIDIA Parabricks**: FQ2BAM tool and suite overview. ([FQ2BAM][pbr-fq2bam], [overview][pbr-overview])\n",
    "7. Taylor-Weiner A. *et al.* (2019) **Scaling computational genomics with GPUs**. *Genome Biology*. ([article][gpu-scaling])\n",
    "8. **bcftools** manual and consensus how-to. ([manual][bcftools-manual], [how-to][bcftools-consensus])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
