{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c47dad",
   "metadata": {},
   "source": [
    "# From FASTQ to **Personalized FASTA** for Genome Language Models  \n",
    "**fastp ➜ Parabricks FQ2BAM (GPU WGS) ➜ Parabricks HaplotypeCaller (GPU) ➜ bcftools filter & consensus**\n",
    "\n",
    "---\n",
    "\n",
    "Modern genome language models (GLMs) benefit from **subject-specific sequences** rather than a generic reference. This notebook introduces a streamlined, GPU-accelerated pipeline that turns raw short-read WGS FASTQs into a **consensus FASTA** suitable for GLM pretraining or fine-tuning—while following community best practices.\n",
    "\n",
    "We’ll cover the historical context and the “why” of each step:\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Read preprocessing with **fastp**\n",
    "\n",
    "Early NGS workflows chained multiple tools for QC, adapter removal, and quality trimming (e.g., separate programs for each task), incurring I/O overheads and slower turnarounds. **fastp** unified these operations into a single, ultra-fast, multi-threaded preprocessor with integrated QC reports, adapter/quality trimming, poly-G tail handling for two-color chemistries, and UMI support—all in one binary ([fastp paper][fastp-paper], [fastp GitHub][fastp-github]).\n",
    "\n",
    "**Typical command (example):**\n",
    "```bash\n",
    "fastp -i sample_R1.fastq.gz -I sample_R2.fastq.gz \\\n",
    "      -o sample.trim.R1.fq.gz -O sample.trim.R2.fq.gz \\\n",
    "      --detect_adapter_for_pe --cut_mean_quality 20 \\\n",
    "      --length_required 50 --thread 16 --html fastp.html --json fastp.json\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Mapping & BAM production with **Parabricks FQ2BAM** (GPU WGS)\n",
    "\n",
    "Short-read WGS mapping crystallized around **BWA-MEM** (2013), balancing speed and accuracy across read lengths and supporting paired-end/chimeric alignment ([BWA-MEM][bwa-mem]). Alignments are stored in the SAM/BAM format introduced by Li *et al.* (2009), now a standard for NGS reads and random access to large genomes ([SAM/BAM][sam-bam]). **GATK Best Practices** standardized downstream steps (mark duplicates, base quality score recalibration, etc.) for reproducible variant discovery ([GATK Best Practices][gatk-best-practices]).\n",
    "\n",
    "**NVIDIA Parabricks** ports this canonical CPU pipeline to GPUs. The **FQ2BAM** tool wraps **BWA-MEM** and performs sorting, duplicate marking, and (optionally) BQSR in one GPU-accelerated stage, delivering **CPU-parity results** with large wall-clock speedups ([Parabricks FQ2BAM][pbr-fq2bam], [Parabricks overview][pbr-overview]). At population scale, GPU acceleration is a key enabler; studies report **>200× runtime decreases and \\~5–10× cost reductions** relative to CPUs ([GPU genomics scaling][gpu-scaling]).\n",
    "\n",
    "**Typical command (example):**\n",
    "\n",
    "```bash\n",
    "pbrun fq2bam \\\n",
    "  --ref hg38.fa \\\n",
    "  --in-fq sample.trim.R1.fq.gz sample.trim.R2.fq.gz \\\n",
    "  --out-bam sample.bam \\\n",
    "  --knownSites dbsnp.vcf.gz \\\n",
    "  --markdups --BQSR --num-threads 32\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Germline variant calling with **Parabricks HaplotypeCaller** (GPU)\n",
    "\n",
    "**GATK HaplotypeCaller** shifted from pileup-based genotyping to **local de-novo assembly in “active regions”**, improving accuracy in complex contexts and producing either VCF or gVCF for joint genotyping ([HaplotypeCaller docs][haplotypecaller-docs]). Parabricks provides a GPU-accelerated implementation that mirrors GATK behavior with greatly reduced runtime, enabling rapid turnarounds without altering scientific outputs ([Parabricks overview][pbr-overview]).\n",
    "\n",
    "**Typical command (example):**\n",
    "\n",
    "```bash\n",
    "pbrun haplotypecaller \\\n",
    "  --ref hg38.fa \\\n",
    "  --in-bam sample.bam \\\n",
    "  --out-variants sample.g.vcf.gz \\\n",
    "  --emit-ref-confidence GVCF \\\n",
    "  --gvcf\n",
    "```\n",
    "\n",
    "> **Option:** Joint-genotype multiple gVCFs (e.g., `pbrun genotypegvcf`), then proceed with filtering.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Filtering & **consensus FASTA** with **bcftools**\n",
    "\n",
    "After variant calling, apply **transparent, auditable filters**—e.g., depth (DP), genotype quality (GQ), strand bias (FS), mapping quality (MQ), allele balance (AB)—before generating a personalized FASTA. The **bcftools** toolkit provides both filtering and a **`consensus`** subcommand that applies variants onto a reference to yield a consensus/individualized sequence ([bcftools manual][bcftools-manual], [bcftools consensus how-to][bcftools-consensus]).\n",
    "\n",
    "**Filtering examples (tune to your coverage & organism):**\n",
    "\n",
    "```bash\n",
    "# Hard filters (illustrative thresholds)\n",
    "bcftools filter -i 'TYPE=\"snp\" && DP>=10 && GQ>=20 && MQ>=40' sample.vcf.gz \\\n",
    "  -Oz -o sample.filtered.vcf.gz\n",
    "tabix -p vcf sample.filtered.vcf.gz\n",
    "```\n",
    "\n",
    "**Create a consensus FASTA** (choose haplotype handling):\n",
    "\n",
    "* **Haploid or pick a phase:** `-H 1` or `-H 2`\n",
    "* **IUPAC codes** for heterozygous sites: `--iupac-codes`\n",
    "\n",
    "```bash\n",
    "# Apply variants to the reference to build a subject-specific FASTA\n",
    "cat hg38.fa | bcftools consensus \\\n",
    "  --sample SAMPLE_ID \\\n",
    "  --haplotype 1 \\\n",
    "  sample.filtered.vcf.gz > sample.consensus.fa\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Why this matters for **Genome LMs**\n",
    "\n",
    "GLMs trained on **individualized sequences** can capture real genetic variation (SNPs/indels) instead of the “average” reference. The pipeline above keeps the **scientific lineage intact** (fastp → BWA-MEM/SAM/BAM → GATK Best Practices → HaplotypeCaller) while leveraging **GPU acceleration** to shorten iteration cycles—crucial when generating many per-sample FASTAs for large-scale ML ([BWA-MEM][bwa-mem], [SAM/BAM][sam-bam], [GATK Best Practices][gatk-best-practices], [HaplotypeCaller docs][haplotypecaller-docs], [Parabricks overview][pbr-overview]).\n",
    "\n",
    "\n",
    "<!-- Reference-style link definitions -->\n",
    "\n",
    "[fastp-paper]: https://academic.oup.com/bioinformatics/article/34/17/i884/5093234 \"fastp: an ultra-fast all-in-one FASTQ preprocessor\"\n",
    "[fastp-github]: https://github.com/OpenGene/fastp \"OpenGene/fastp\"\n",
    "[bwa-mem]: https://arxiv.org/pdf/1303.3997 \"Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM\"\n",
    "[sam-bam]: https://academic.oup.com/bioinformatics/article/25/16/2078/204688 \"Sequence Alignment/Map format and SAMtools\"\n",
    "[gatk-best-practices]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4243306/ \"From FastQ data to high confidence variant calls (GATK Best Practices)\"\n",
    "[haplotypecaller-docs]: https://gatk.broadinstitute.org/hc/en-us/articles/21905025322523-HaplotypeCaller \"GATK HaplotypeCaller documentation\"\n",
    "[pbr-fq2bam]: https://docs.nvidia.com/clara/parabricks/4.4.0/Documentation/ToolDocs/man_fq2bam.html \"Parabricks FQ2BAM (BWA-MEM + GATK)\"\n",
    "[pbr-overview]: https://docs.nvidia.com/clara/parabricks/4.3.1/index.html \"NVIDIA Parabricks overview\"\n",
    "[gpu-scaling]: https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1836-7 \"Scaling computational genomics to millions of individuals with GPUs\"\n",
    "[bcftools-manual]: https://samtools.github.io/bcftools/bcftools.html \"bcftools manual\"\n",
    "[bcftools-consensus]: https://samtools.github.io/bcftools/howtos/consensus-sequence.html \"bcftools consensus how-to\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd678df",
   "metadata": {},
   "source": [
    "## Import wrapper functions for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9aefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from typing import Dict\n",
    "\n",
    "# Configurations\n",
    "THREADS=16\n",
    "MEMORY=128\n",
    "MIN_VAR_QUAL=30\n",
    "MIN_DEPTH=6\n",
    "MIN_VAR_FREQ=0.6  # For haploid, variants should be majority frequency or greater\n",
    "MAX_DEPTH=500\n",
    "\n",
    "def trim_fastq(\n",
    "        job: Dict[str,str],\n",
    "        min_illumina_quality:int=20,\n",
    "        min_illumina_length:int=50,\n",
    "        min_illumina_complexity:int=30):\n",
    "    print(job['OUTPUT_PREFIX'])\n",
    "    cmd = [\n",
    "        \"/opt/fastp\",\n",
    "        \"-i\", job[\"UNPROCESSED_FASTQ_R1\"],\n",
    "        \"-I\", job[\"UNPROCESSED_FASTQ_R2\"],\n",
    "        \"-o\", job[\"FASTQ_R1\"],\n",
    "        \"-O\", job[\"FASTQ_R2\"],\n",
    "        \"-w\", \"16\",\n",
    "        \"-q\", str(min_illumina_quality),\n",
    "        \"--detect_adapter_for_pe\",\n",
    "        \"--length_required\", str(min_illumina_length),\n",
    "        \"-c\", \"-y\", \"-Y\", str(min_illumina_complexity)\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"w\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "def alignment(job: Dict[str,str]):\n",
    "    print(job['OUTPUT_PREFIX'])\n",
    "    cmd = [\n",
    "        \"pbrun\", \"fq2bam\",\n",
    "        \"--ref\", job[\"REF_FASTA\"],\n",
    "        \"--in-fq\", job[\"FASTQ_R1\"], job[\"FASTQ_R2\"],\n",
    "        \"--out-bam\", job[\"BAM_FILE\"],\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "def variant_calling(job:Dict[str,str]):\n",
    "    print(job['OUTPUT_PREFIX'])\n",
    "    cmd = [\n",
    "        \"pbrun\", \"haplotypecaller\",\n",
    "        \"--ref\", job[\"REF_FASTA\"],\n",
    "        \"--in-bam\", job[\"BAM_FILE\"],\n",
    "        \"--out-variants\", job[\"RAW_VCF\"],\n",
    "        \"--ploidy\", \"1\",\n",
    "        \"--minimum-mapping-quality\", \"20\",\n",
    "        \"--haplotypecaller-options\", \"-standard-min-confidence-threshold-for-calling 10\"\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "def basic_snp_filter(job:Dict[str,str]):\n",
    "    print(job['OUTPUT_PREFIX'])\n",
    "    cmd = [\n",
    "        \"bcftools\", \"view\",\n",
    "        \"-i\", f\"QUAL >= {MIN_VAR_QUAL} && INFO/DP >= {MIN_DEPTH} && INFO/DP <= {MAX_DEPTH}\",\n",
    "        job[\"RAW_VCF\"],\n",
    "        \"-O\", \"v\",\n",
    "        \"-o\", job[\"FILTERED_VCF\"]\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "def haploid_snp_filter(job:Dict[str,str]):\n",
    "    print(job['OUTPUT_PREFIX'])\n",
    "    cmd = [\n",
    "        \"bcftools\", \"view\",\n",
    "        \"-i\", f\"FORMAT/AD[0:1]/(FORMAT/AD[0:0]+FORMAT/AD[0:1]) >= {MIN_VAR_FREQ}\",\n",
    "        job[\"FILTERED_VCF\"],\n",
    "        \"-O\", \"v\",\n",
    "        \"-o\", job[\"HIGH_CONF_VCF\"]\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        subprocess.run(\n",
    "            cmd,\n",
    "            stdout=f_out,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "def generate_fasta(job:Dict[str,str]):\n",
    "    print(job['OUTPUT_PREFIX'])\n",
    "    cmd1 = [\n",
    "        \"bcftools\", \"norm\",\n",
    "        \"-f\", job[\"REF_FASTA\"],\n",
    "        \"-m\", \"-both\",\n",
    "        job[\"HIGH_CONF_VCF\"],\n",
    "        \"-O\", \"v\",\n",
    "        \"-o\", f\"{job['HIGH_CONF_VCF']}.normalized.vcf\"\n",
    "    ]\n",
    "    cmd2 = [\n",
    "        \"bcftools\", \"view\",\n",
    "        f\"{job['HIGH_CONF_VCF']}.normalized.vcf\", \n",
    "        \"-Oz\", \"-o\", f\"{job['HIGH_CONF_VCF']}.normalized.vcf.gz\", \n",
    "    ]\n",
    "    cmd3 = [\"bcftools\", \"index\", f\"{job['HIGH_CONF_VCF']}.normalized.vcf.gz\"]\n",
    "    cmd4 = [\n",
    "        \"bcftools\", \"consensus\",\n",
    "        \"-f\", job[\"REF_FASTA\"],\n",
    "        \"-o\", job[\"CONSENSUS_FASTA\"],\n",
    "        f\"{job['HIGH_CONF_VCF']}.normalized.vcf.gz\"\n",
    "    ]\n",
    "    with open(job[\"LOG_FILE\"], \"a\") as f_out:\n",
    "        for cmd in [cmd1,cmd2,cmd3,cmd4]:\n",
    "            subprocess.run(\n",
    "                cmd,\n",
    "                stdout=f_out,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                check=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f669f1e",
   "metadata": {},
   "source": [
    "### Preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf08ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/workspace/datasets\"\n",
    "study_dir = f\"{base}/haploid\"\n",
    "bam_dir = f\"{study_dir}/bam\"\n",
    "vcf_dir = f\"{study_dir}/vcf\"\n",
    "tmp_dir = f\"{study_dir}/tmp\"\n",
    "fastq_dir = f\"{study_dir}/fastq\"\n",
    "fastq_raw_delimiters = [\"_unprocessed_illumina_\"]\n",
    "\n",
    "# Create directories for files\n",
    "!mkdir -p $base\n",
    "!mkdir -p $study_dir\n",
    "!mkdir -p $bam_dir\n",
    "!mkdir -p $vcf_dir\n",
    "!mkdir -p $tmp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess fasta file\n",
    "fasta_file = f\"{study_dir}/fasta/GCA_000027005.1_ASM2700v1_genomic.fna\"\n",
    "genomic_gtf = f\"{study_dir}/fasta/genomic.gtf\"\n",
    "\n",
    "# Index fasta with BWA\n",
    "!/opt/bwa/bwa index $fasta_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2182c2",
   "metadata": {},
   "source": [
    "### Build jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_files = [f\"{fastq_dir}/{i}\" for i in os.listdir(fastq_dir) if all([j in i for j in fastq_raw_delimiters])]\n",
    "sample_names = [\"your-sample-names\"]\n",
    "# My process to identify filenames based on path\n",
    "# sample_names = sorted(list(set([i.split(\"fastq_unprocessed_illumina_\")[-1].split(\"_R\")[0] for i in fastq_files]))) \n",
    "\n",
    "jobs = [\n",
    "    {\n",
    "        \"UNPROCESSED_FASTQ_R1\":[i for i in fastq_files if sample_name in i and \"_R1.\" in i][0],\n",
    "        \"UNPROCESSED_FASTQ_R2\":[i for i in fastq_files if sample_name in i and \"_R2.\" in i][0],\n",
    "        \"FASTQ_R1\":[i.replace(\"_unprocessed_\",\"_trimmed_\") for i in fastq_files if sample_name in i and \"_R1.\" in i][0],\n",
    "        \"FASTQ_R2\":[i.replace(\"_unprocessed_\",\"_trimmed_\") for i in fastq_files if sample_name in i and \"_R2.\" in i][0],\n",
    "        \"REF_FASTA\":fasta_file,\n",
    "        \"ANNOTATION_GTF\":genomic_gtf,\n",
    "        \"OUTPUT_PREFIX\":sample_name,\n",
    "        \"BAM_FILE\":f\"{study_dir}/bam/{sample_name}.sorted.bam\",\n",
    "        \"RAW_VCF\":f\"{study_dir}/vcf/{sample_name}.raw.vcf\",\n",
    "        \"FILTERED_VCF\":f\"{study_dir}/vcf/{sample_name}.filtered.vcf\",\n",
    "        \"HIGH_CONF_VCF\":f\"{study_dir}/vcf/{sample_name}.high_confidence.vcf\",\n",
    "        \"CONSENSUS_FASTA\":f\"{study_dir}/fasta/{sample_name}.consensus.fasta\",\n",
    "        \"STATS_FILE\":f\"{study_dir}/{sample_name}.stats.txt\",\n",
    "        \"LOG_FILE\":f\"{study_dir}/{sample_name}.pipeline.log\",\n",
    "    }\n",
    "    for sample_name in sample_names\n",
    "]\n",
    "print(len(jobs))\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4849349",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in jobs:\n",
    "    trim_fastq(job)\n",
    "    alignment(job)\n",
    "    variant_calling(job)\n",
    "    basic_snp_filter(job)\n",
    "    haploid_snp_filter(job)\n",
    "    generate_fasta(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c24b5f",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Chen S. *et al.* (2018) **fastp**: an ultra-fast all-in-one FASTQ preprocessor. *Bioinformatics*. ([paper][fastp-paper], [code][fastp-github])\n",
    "2. Li H. (2013) **BWA-MEM**: aligning sequence reads and contigs. *arXiv*. ([preprint][bwa-mem])\n",
    "3. Li H. *et al.* (2009) **The SAM/BAM format and SAMtools**. *Bioinformatics*. ([article][sam-bam])\n",
    "4. Van der Auwera G.A. *et al.* (2013) **From FastQ data to high-confidence variant calls**. *Curr Protoc Bioinformatics*. ([overview][gatk-best-practices])\n",
    "5. **GATK HaplotypeCaller** documentation. ([page][haplotypecaller-docs])\n",
    "6. **NVIDIA Parabricks**: FQ2BAM tool and suite overview. ([FQ2BAM][pbr-fq2bam], [overview][pbr-overview])\n",
    "7. Taylor-Weiner A. *et al.* (2019) **Scaling computational genomics with GPUs**. *Genome Biology*. ([article][gpu-scaling])\n",
    "8. **bcftools** manual and consensus how-to. ([manual][bcftools-manual], [how-to][bcftools-consensus])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
